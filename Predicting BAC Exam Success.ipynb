{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6eec650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/amema/Downloads/bac-mauritanie-2022-predictive-modeling-challeng/train_set.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/amema/Downloads/bac-mauritanie-2022-predictive-modeling-challeng/test_set.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53507c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81d7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# definir les noms des mois en arabe et en francais\n",
    "arabic_months = ['يناير', 'فبراير', 'مارس', 'أبريل', 'مايو', 'يونيو', 'يوليو', 'أغسطس', 'سبتمبر', 'أكتوبر', 'نوفمبر', 'ديسمبر']\n",
    "french_months = ['janv.', 'fév.', 'mars', 'avr.', 'mai', 'juin', 'juil.', 'août', 'sep.', 'oct.', 'nov.', 'déc.']\n",
    "\n",
    "\n",
    "#  une expression réguliére pour extraire le jour, le mois et l'année séparément\n",
    "arabic_regex = r'(\\d{1,2})\\s+(' + '|'.join(arabic_months) + r')\\s+(\\d{4})'\n",
    "french_regex = r'(\\d{1,2})\\s+(' + '|'.join(french_months) + r')\\s+(\\d{4})'\n",
    "\n",
    "# appliquer l'expression réguliére et créer un objet datetime\n",
    "def convert_date(date_string):\n",
    "    if re.search(arabic_regex, date_string):\n",
    "        return datetime.strptime(re.search(arabic_regex, date_string).group(1)+' '+str(arabic_months.index(re.search(arabic_regex, date_string).group(2))+1)+' '+re.search(arabic_regex, date_string).group(3), '%d %m %Y')\n",
    "    elif re.search(french_regex, date_string):\n",
    "        return datetime.strptime(re.search(french_regex, date_string).group(1)+' '+str(french_months.index(re.search(french_regex, date_string).group(2))+1)+' '+re.search(french_regex, date_string).group(3), '%d %m %Y')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "train_data['DateNaissance'] = train_data['DateNaissance'].apply(convert_date)\n",
    "test_data['DateNaissance'] = test_data['DateNaissance'].apply(convert_date)\n",
    "\n",
    "# convertir le format  datetime au format \"YYYY-MM-DD\" \n",
    "train_data['DateNaissance'] = train_data['DateNaissance'].dt.strftime('%Y-%m-%d')\n",
    "test_data['DateNaissance'] = test_data['DateNaissance'].dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c60c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la date de naissance  la plus fréquente\n",
    "most_frequent_date = train_data['DateNaissance'].mode()[0]\n",
    "most_frequent_date_ = test_data['DateNaissance'].mode()[0]\n",
    "\n",
    "\n",
    "# Imputer les valeurs manquantes avec la date la plus fréquente\n",
    "train_data['DateNaissance'] = train_data['DateNaissance'].fillna(most_frequent_date)\n",
    "test_data['DateNaissance'] = test_data['DateNaissance'].fillna(most_frequent_date_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b8a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today()\n",
    "today_2021 = today.replace(year=2021)\n",
    "today_2022 = today.replace(year=2022)\n",
    "\n",
    "# ajouter une nouvelle colonne avec la date d'aujourd'hui mais avec l'année 2021/2022 \n",
    "train_data['Today2021'] = today_2021.strftime('%Y-%m-%d')\n",
    "test_data['Today2022'] = today_2022.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# covertir la colonne 'DateNaissance' au format datetime\n",
    "train_data['DateNaissance'] = pd.to_datetime(train_data['DateNaissance'])\n",
    "test_data['DateNaissance'] = pd.to_datetime(test_data['DateNaissance'])\n",
    "\n",
    "\n",
    "# calculer l'age de chaque etudiant\n",
    "train_data['Age'] = (today_2021 - train_data['DateNaissance']) // pd.Timedelta(days=365.25)\n",
    "test_data['Age'] = (today_2022 - test_data['DateNaissance']) // pd.Timedelta(days=365.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504504d0",
   "metadata": {},
   "source": [
    "###  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b9ef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Sélection des caractéristiques (features) et la variable cible (target)\n",
    "categorical_features = ['Etablissement', 'Serie,x','Centre','Willaya', 'moughataa']\n",
    "numeric_features = ['Age']\n",
    "target = 'Decision'\n",
    "\n",
    "# Concaténation des ensembles d'entraînement et de test\n",
    "all_data = pd.concat([train_data[categorical_features + numeric_features], test_data[categorical_features + numeric_features]], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Prétraitement des variables catégorielles\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "cat_transformer.fit(all_data)\n",
    "\n",
    "# Encodage # Prétraitement des variables catégorielles\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "cat_transformer.fit(all_data[categorical_features])\n",
    "\n",
    "# Prétraitement de la variable numérique\n",
    "num_transformer = StandardScaler()\n",
    "num_transformer.fit(all_data[numeric_features])\n",
    "\n",
    "# Création du transformateur de colonnes des variables catégorielles de l'ensemble d'entraînement\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, categorical_features),\n",
    "        ('num', num_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Encodage des variables catégorielles de l'ensemble d'entraînement\n",
    "X_train_encoded = preprocessor.fit_transform(train_data[categorical_features + numeric_features])\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test encodés\n",
    "X_test_encoded = preprocessor.transform(test_data[categorical_features + numeric_features])\n",
    "y_train = train_data[target]\n",
    "\n",
    "# Modèle Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Entraînement du modèle avec validation croisée\n",
    "scores = cross_val_score(model, X_train_encoded, y_train, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Entraînement du modèle sur l'ensemble d'entraînement complet\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Faire la prédiction sur le nouveau jeu de données\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "# Ajouter la prédiction en tant que colonne \"Decision\" dans le nouveau jeu de données\n",
    "test_data['Decision'] = y_pred\n",
    "\n",
    "# Ajouter la probabilité que la décision soit \"Admis\" dans le nouveau jeu de données\n",
    "y_prob = model.predict_proba(X_test_encoded)\n",
    "test_data['Predicted'] = y_prob[:,1]\n",
    "\n",
    "data = test_data.loc[:, ['ID', 'Predicted']]\n",
    "\n",
    "# Sauvegarde du nouveau jeu de données avec les prédictions et les ID\n",
    "data.to_csv(\"C:/Users/amema/OneDrive/Desktop/DataChal/RandomForestC2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d58ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (data['Predicted'] > 0.5).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15b517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
